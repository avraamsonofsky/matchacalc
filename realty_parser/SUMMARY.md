# Сводка проекта: Универсальный парсер данных недвижимости

## Что было создано

Создан универсальный парсер для извлечения данных (цена, площадь, район, год) с трех сайтов:
- Cian.ru
- Avito.ru  
- Yandex Realty

## Реализованные варианты парсеров

### 1. **parser_v1_requests.py** - Requests + BeautifulSoup
- ✅ Быстрый и легковесный
- ✅ Подходит для статического контента
- ✅ Минимальные зависимости

### 2. **parser_v2_selenium.py** - Selenium
- ✅ Работает с динамическим контентом
- ✅ Требует ChromeDriver
- ✅ Надежный для JS-контента

### 3. **parser_v3_playwright.py** - Playwright
- ✅ Современная альтернатива Selenium
- ✅ Лучшая поддержка современных веб-приложений
- ✅ Требует установки браузеров

### 4. **parser_v4_mcp.py** и **mcp_parser_real.py** - MCP Parser
- ✅ Использует Model Context Protocol
- ✅ Интеграция с AI-инструментами
- ✅ Требует настройки MCP сервера

### 5. **universal_parser.py** - Универсальный парсер
- ✅ Автоматический выбор метода
- ✅ Пробует методы по очереди при неудаче
- ✅ Удобный интерфейс

## Тестовые скрипты

- **test_parsers.py** - Тестирование отдельных парсеров
- **test_all_parsers.py** - Комплексное тестирование всех вариантов
- **test_mcp_parser.py** - Тестирование MCP парсера
- **run_mcp_test.py** - Демонстрация MCP парсинга

## Структура данных

Все парсеры возвращают словарь:
```python
{
    'price': '50000000',      # Цена в рублях
    'area': '150',            # Площадь в м²
    'district': 'Внутри МКАД вне ТТК',  # Район
    'year': '2020'            # Год постройки
}
```

## Быстрый старт

```bash
# Установка
pip install -r requirements.txt

# Использование
python -c "from universal_parser import parse_url; print(parse_url('URL'))"

# Тестирование
python test_all_parsers.py
```

## Тестовые URL

1. Cian: `https://lyubertsy.cian.ru/sale/commercial/307487135/...`
2. Avito: `https://www.avito.ru/moskva/kommercheskaya_nedvizhimost/...`
3. Yandex: `https://realty.yandex.ru/offer/7567098664232911117/`

## Особенности реализации

1. **Множественные селекторы** - каждый парсер пробует несколько способов извлечения данных
2. **Обработка ошибок** - все парсеры возвращают структурированные результаты даже при ошибках
3. **Универсальный интерфейс** - все парсеры имеют одинаковый API
4. **Автоматический выбор** - UniversalParser автоматически выбирает лучший метод

## Следующие шаги

1. Протестировать все парсеры на реальных URL
2. Доработать селекторы под актуальную структуру сайтов
3. Добавить обработку прокси и ротацию User-Agent
4. Настроить MCP сервер для продакшена

## Файлы проекта

- `requirements.txt` - Зависимости
- `README.md` - Основная документация
- `USAGE.md` - Подробная инструкция по использованию
- `parser_v*.py` - Реализации парсеров
- `universal_parser.py` - Универсальный интерфейс
- `test_*.py` - Тестовые скрипты
